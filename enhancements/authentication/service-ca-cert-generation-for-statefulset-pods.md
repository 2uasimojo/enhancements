---
title: service-ca-cert-generation-for-statefulset-pods
authors:
  - "@mtrmac"
reviewers:
  - TBD
approvers:
  - TBD
creation-date: 2021-03-01
last-updated: 2021-03-01
status: implementable
see-also:
replaces:
superseded-by:
---

# Service CA Certificate Generation for StatefulSet Pods

## Release Signoff Checklist

- [ ] Enhancement is `implementable`
- [ ] Design details are appropriately documented from clear requirements
- [ ] Test plan is defined
- [ ] Operational readiness criteria is defined
- [ ] Graduation criteria for dev preview, tech preview, GA
- [ ] User-facing documentation is created in [openshift-docs](https://github.com/openshift/openshift-docs/)

## Summary

The Service CA-generated certificates _for headless services_ include
`*.${service.name}.${service.namespace}.svc` and
`*.${service.name}.${service.namespace}.svc.cluster.local`
as subjects,
to allow TLS-protected communication between StatefulSet pods.

## Motivation

StatefulSet-managed pods often need to communicate with each other.
This traffic may need to be TLS-protected; because it is cluster-internal,
and necessary for deploying such a StatefulSet, letting the cluster automatically
manage the certificates is a natural extension to the same feature already
provided by the Service CA to allow TLS use with services.

### Goals

Allow deploying StatefulSets with pods that communicate with each other using TLS,
without having to manually generate certificates for these pods.

### Non-Goals

- Provide certificates for `127.0.0.1`, `localhost`, or NodeIP service endpoints

  (See discussion in “Implementation Details/Notes/Constraints”)

- Provide individual certificates that uniquely identify individual pods in the StatefulSet,
  protecting the intra-StatefulSet communication against re-routing to unintended members
  of that StatefulSet
  (or to a different StatefulSet attached to the same headless service).

## Proposal

Currently, a service annotated with
a `service.beta.openshift.io/serving-cert-secret-name: $secretName`
requests the `service-ca` controller to generate a secret `$secretName`
containing a certificate+key pair for `${service.name}.${service.namespace}.svc`
(and a `….cluster.local`) as subjects.

For headless services, generate certificates that include two more subjects,
`*.${service.name}.${service.namespace}.svc` and
`*.${service.name}.${service.namespace}.svc.cluster.local`,
intended to match `${pod.hostname}.${service.name}.${service.namespace}.svc…`
served in DNS for endpoints of that service
(and in particular, for StatefulSets,
`${statefulset.name}-${podID}.${service.name}.${service.namespace}.svc…`).


### User Stories

#### Creating a TLS-protected StatefulSet

**Note:** This only ensures that the communication happens between members of the StatefulSet,
it does not provide individual identity.

- The user creates/annotates a headless service with
  `service.beta.openshift.io/serving-cert-secret-name: $secretName`
- The Service CA generates a `$secretName` secret, with type: `kubernetes.io/tls`,
  containing a single certificate and private key for
  - `${service.name}.${service.namespace}.svc`
  - `${service.name}.${service.namespace}.svc.cluster.local`
  - `*.${service.name}.${service.namespace}.svc`
  - `*.${service.name}.${service.namespace}.svc.cluster.local`
- The user creates/updates a StatefulSet for the application to contain use the generated secret

#### Scaling the StatefulSet Up/Down

Once the secret is generated, users can scale the StatefulSet with no change to the usual process.

#### Using TLS to Guarantee Individual Identity of StatefulSet Pods, or StatefulSets

To ensure that a compromised StatefulSet pod can’t impersonate other pods from the
same StatefulSet,
or any other pods attached ot the same headless service
(if this goal is achievable for the application,
i.e. if the pods treat the intra-StatefulSet communication as untrusted
and can plausibly protect against a rogue StatefulSet member):

- Use something else, not the certificates generated by the Service CA.
- **Don’t accept the Service CA as a valid root of trust for connections intended
  for individual StatefulSet pods**.

#### Certificate Expiration, Manual Secret Regeneration, CA Rotations

No change to existing Service CA use.

### Implementation Details/Notes/Constraints

#### Not Generating Certificates for `127.0.0.1`, `localhost`, or NodeIPs

Giving out certificates from widely-accepted CAs (like the service CA)
with these names makes no sense because they don’t specify any service identity,
e.g. any compromised serviceA would get a `localhost` or nodeIP certificate
that is acceptable for connections intended to connect to serviceB.

(Reportedly some OSes do actually query `localhost` on DNS on the net:
https://archive.cabforum.org/pipermail/public/2015-June/005673.html )

If a client wants to connect to _only_ a “true localhost” service,
a service CA-signed certificate does not provide that property.
The best way to do that is to do it directly inside the process,
without using TLS (and the associated cryptography overhead) at all.
Second best is to rely on known properties of the environment,
i.e. to assume that 127.0.0.1 is localhost-only
and to use a non-TLS connection on that address.

If a _pod_ had to use TLS for localhost for some reason, the closest to a right way to do that
(relying on TLS to verify that only loopback connections happen) is to:
- Create a temporary CA (specific to the individual pod for)
- Generate, and have that CA sign a localhost certificate (specific to the individual pod)
- Set up the CA certificate as a trusted root
- _Irreversibly erase_ the CA private key
- Set up the pod with the generated localhost certificate+private key.
- (This doesn’t benefit from service-ca involvement at all.)

Similarly single-purpose CA could be set up for NodeIP services
(if it makes sense to connect to node IP addresses directly at all)
so that the client connects to the desired NodeIP service
instead of to any NodeIP service.

### Risks and Mitigations

The only mitigations for the risks below are not to use this feature,
(and prevent untrusted users from using it — using an admission controller?)
so that the wildcard certificate is not created at all,
or perhaps $somehow ensure that any users/code with access to the wildcard certificate
is not likely to be compromised.

#### Unexpected DNS Collisions in the Future

https://github.com/kubernetes/dns/blob/master/docs/specification.md
only specifies what DNS records must exist, not what must not exist,
so the generated wildcard certificate could match unwanted DNS entries.

The DNS specification does not even guarantee that different namespaces
will use different DNS subtrees.

Given the existing naming conventions of in-cluster DNS,
such unexpected collisions seem somewhat unlikely,
but can’t be ruled out in advance.

#### No Individual Pod Identity

The wildcard certificate does not protect the intra-StatefulSet communication
against re-routing to unintended members of that StatefulSet
(or to a different StatefulSet attached to the same headless service).

In addition, any application that uses a different set of certificates to achieve that goal
**must not accept the Service CA as a valid root of trust for connections intended
for individual StatefulSet pods**.

## Design Details

### Open Questions

N/A

### Test Plan

Unit and e2e tests similar to the existing service certificate tests, both in structure and scope.

Ensure that upgrades (or alternatively any controller re-syncs)
cause re-generation of certificates for headless services
to include the wildcard subjects, if they are missing.

### Graduation Criteria

#### Dev Preview -> Tech Preview

- Ability to utilize the enhancement end to end
- End user documentation (TBD: where?)
- Sufficient test coverage
- Gather feedback from users rather than just developers
- Enumerate service level indicators (SLIs), expose SLIs as metrics
  TBD?
- Write symptoms-based alerts for the component(s)
  TBD?

#### Tech Preview -> GA

- More testing (upgrade, downgrade, scale)
- Sufficient time for feedback
- Available by default
- Backhaul SLI telemetry
  TBD?
- Document SLOs for the component
  TBD?
- Conduct load testing
  TBD?

### Upgrade / Downgrade Strategy

Upgrading to a version that adds the feature will trigger a regeneration of secrets
requested for headless services.
The previously-generated certificates will continue to be valid for their original lifetime,
and previously-deployed components can continue to use them as before.

If the upgrade to the first version that generates the wildcards
also included an operator relying on this functionality,
and the old version of the Service CA were still running,
only the old version of the secret (with no wildcards) would be generated,
and that could lead to surprising outcomes for a StatefulSet relying on the wildcard.
Eventually, after the Service CA is upgrades,
it will re-generate the secret to include the wildcard subjects.

So, OpenShift components can either not use this feature until x.N+2,
or design their StatefulSets to fail/wait until the Service CA is upgraded
and a new wildcard certificate is available.

Previous versions of the Service CA do not check subjects of the generated secrets
(only that the secrets are signed by the currently-valid service CA root),
so the wildcard certificates will continue to be work on downgrade,
probably at least enough to allow downgraded operators to revert to whatever they were doing before.

### Version Skew Strategy

See above for the case of OpenShift components relying on wildcard certificates.

## Implementation History

PR to generate wildcard certificates: TBD
WIP PR to generate strict pod identities: https://github.com/openshift/service-ca-operator/pull/144

## Drawbacks

See Risks above.

## Alternatives

### Do Nothing
Manage the StatefulSet certificates manually, using some other CA.

### Modify StatefulSet to Support Individual Per-Pod Secrets
Instead of generating a single large secret with multiple certificates/keys,
provide each pod in a StatefulSet with a separate secret containing only the certificate+key
for that single pod.

That would automatically prevent a compromised StatefulSet pod from impersonating
any other pod in the StatefulSet.

The StatefulSet pod template does not have any templating mechanism
that would allow a ${podID}-dependent value to be used for a secret name or a volume mount;
there’s only StatefulSet.spec.volumeClaimTemplates , which is not practical to use.

(Upstream https://github.com/kubernetes/kubernetes/issues/40651 only ends up
discussing environment variables (which work via the downward API).)

So, we would need to add a more general templating mechanism to StatefulSet,
either as something specific to secrets
or some very general text/YAML substitution mechanism.

### Generate a Single Secret with Per-Pod Certificates

Instead of using a wildcard certificate that can match unknown future DNS entries,
generate certificates specific to individual pods:
The user would add a `service.beta.openshift.io/serving-cert-secret-name: $secretName` annotation,
and a `$secretName` secret is generated, which can be mounted in the StatefulSet’s pods.
The individual pods would be responsible using the appropriate certificate.

The downside is that creating/scaling up a StatefulSet triggers
both creating the StatefulSet pods and a secret creation/update,
which race against each other;
So, the pods would have to explicitly account for that race,
by failing, or waiting, if a certificate for their identity is not found.

### Generate Multi-Service Certificates
So that applications can simply use a single certificate on all listening ports,
generate a single certificate that signs multiple ~unrelated services as subjects
(combining the StatefulSet per-pod subjects and ClusterIP services,
or a ClusterIP service with NodePort service),

In the most general case, this is not possible to do using the current annotation approach,
because services choose pods by pod labels,
i.e. the set of services served by a single pod at once (which require a shared certificate)
can only be determined once such a pod is created —
and at that point it’s too late to generate a certificate for that pod.
So, this would require defining a new Custom Resource
that allows the user to define service combinations to be signed
(and the user would be resposible for requesting the necessary service combinations).

Generating multi-subject certificates also makes it more difficult
to reason about security properties and to change service routing:
once a single certificate for (serviceA+serviceB) exists,
even if the implementation is later changed
by moving serviceB to a separate set of pods,
a compromised pod with access to the earlier combined certificate
would allow an attacker to continue to impersonate both serviceA and serviceB
(e.g. because the Service CA does not currently allow revoking certificates).

If the different services are served on different ports,
they can trivially use different certificates.

Even for a single port exposed via the different services,
the server should be able to use different certificates based on SNI nowadays
(e.g. via https://golang.org/pkg/crypto/tls/#Config.Certificates ).

## Infrastructure Needed [optional]

N/A
